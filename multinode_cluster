master node ---
sudo adduser hduser
sudo visudo
hduser ALL=(ALL) NOPASSWD:ALL
sudo nano /etc/resolv.conf
nameserver 192.168.72.20
sudo apt update -y
sudo apt install ssh vim pdsh openjdk-8-jdk git -y
sudo apt install net-tools -y
sudo systemctl start ssh
sudo systemctl enable ssh
apache hadoop download frist binary hadoop-3-4-0.tar.gz
or
wget -c -O hadoop.tar.gz https://dlcdn.apache.org/hadoop/common/hadoop-3.2.4/hadoop-3.2.4.tar.gz
sudo mkdir /usr/local/hadoop
cd Download
tar xvzf hadoop-3.3.0.tar.gz
sudo mv hadoop-3.4.0/* /usr/local/hadoop
sudo chown -R hduser:hduser /usr/local/hadoop
nano .bashrc
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_MARPED_HOME=$HADOOP_HOME
export HADOOP_YARN_HOME=$HADOOP_HOME
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
export CLASSPATH=$CLASSPATH:$(hadoop classpath)
export PDSH_RCMD_TYPE=ssh
source .bashrc
creating clone datanode1 2,3
cat ~/.bashrc
copy JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
nano hadoop.env.sh
paste
core-site.sh
<property>
        <name>fs.defaultFS</name>
        <value>hdfs://master:9000</value>
    </property>

hdfs-site.xml

 <property>
        <name>dfs.name.dir</name>
        <value>/usr/local/hadoop/hd-data/nn</value>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>2</value>
    </property>

mapred-site.xml
<property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>mapreduce.application.classpath</name>
        <value>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*</value>
    </property>

  yarn-sie.xml

   <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>master</value>
    </property>

 worker
DN1
DN2
#DN3 ..add later if given add node3 later otherwise add here
datanode1---
ip a
datanode2---
ip a
master----
sudo nano /etc/hostst
192.168.144.129 master
192.168.144.130 DN1
192.168.144.131 DN2
#dn3
ssh confogure
ssh-keygen -t rsa
ssh-copy-id -i ~/.ssh/id_rsa.pub hduser@master
ssh-copy-id -i ~/.ssh/id_rsa.pub hduser@DN1
ssh-copy-id -i ~/.ssh/id_rsa.pub hduser@DN2
scp /etc/hosts hduser@DN1:/home/hduser
scp /etc/hosts hduser@DN2:/home/hduser
scp /usr/local/hadoop/etc/hadoop/core-site.xml hduser@DN1:/usr/local/hadoop/etc/hadoop
scp /usr/local/hadoop/etc/hadoop/core-site.xml hduser@DN2:/usr/local/hadoop/etc/hadoop
scp /usr/local/hadoop/etc/hadoop/hdfs-site.xml hduser@DN1:/usr/local/hadoop/etc/hadoop
scp /usr/local/hadoop/etc/hadoop/hdfs-site.xml hduser@DN2:/usr/local/hadoop/etc/hadoop
scp /usr/local/hadoop/etc/hadoop/yarn-site.xml hduser@DN1:/usr/local/hadoop/etc/hadoop
scp /usr/local/hadoop/etc/hadoop/yarn-site.xml hduser@DN2:/usr/local/hadoop/etc/hadoop
scp /usr/local/hadoop/etc/hadoop/mapred-site.xml hduser@DN1:/usr/local/hadoop/etc/hadoop
scp /usr/local/hadoop/etc/hadoop/mapred-site.xml hduser@DN2:/usr/local/hadoop/etc/hadoop
scp /usr/local/hadoop/etc/hadoop/hadoop-env.sh hduser@DN1:/usr/local/hadoop/etc/hadoop
scp /usr/local/hadoop/etc/hadoop/hadoop-env.sh hduser@DN2:/usr/local/hadoop/etc/hadoop
datanode1-----
sudo cp hosts /etc/hosts
core-site.xml ----same
hdfs-site.xml
<property>
        <name>dfs.data.dir</name>
        <value>/usr/local/hadoop/hd-data/dn</value>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>2</value>
    </property>
mapred-site.xml----same
yarn-site.xml
<property>
        <name>yarn.resourcemanager.hostname</name>
        <value>master</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.local-dirs</name>
        <value>/usr/local/hadoop/hd-data/yarn/data</value>
    </property>
    <property>
        <name>yarn.nodemanager.logs-dirs</name>
        <value>/usr/local/hadoop/hd-data/yarn/logs</value>
    </property>
    <property>
        <name>yarn.nodemanager.disk-health-checker.max-disk-utilization-perdisk-percentage</name>
        <value>99.9</value>
    </property>
    <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
    </property>
    <property>
        <name>yarn.nodemanager.env-whitelist</name>
        <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
    </property>
 workers
 localhost
 copy to dn2 #and dn3
 scp hdfs-site.xml hduser@DN2:/usr/local/hadoop/etc/hadoop
 same for yarn site
 scp yarn-site.xml hduser@DN2:/usr/local/hadoop/etc/hadoop
 master----
 mkdir /usr/local/hadoop/hd-data
 dn1---
 mkdir /usr/loal/hadoop/hd-data
 mkdir /usr/local/hadoop/yarn
 same to dn2 #dn3
 master --
 hadoop namenode -format
 dn2--
sudo cp hosts /etc/hosts
master---
start-dfs.sh
start-yarn.sh
start-all.sh
dn1 -ping master
dn2-ping master
master---
ssh -t hduser@DN1
ssh -t hduser@DN2
------------------------
web---http://master:9870
------------------------
